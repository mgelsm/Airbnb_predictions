{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import machine_learning_helper as machine_learning_helper\n",
    "import metrics_helper as metrics_helper\n",
    "import sklearn.neighbors, sklearn.linear_model, sklearn.ensemble, sklearn.naive_bayes\n",
    "#from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold, train_test_split, ShuffleSplit\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import scipy as sp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_users = pd.read_csv(\"cleaned_train_user.csv\")\n",
    "df_test_users = pd.read_csv(\"cleaned_test_user.csv\")\n",
    "df_time_mean_user_id = pd.read_csv(\"time_mean_user_id.csv\")\n",
    "df_time_total_user_id = pd.read_csv(\"time_total_user_id.csv\")\n",
    "df_total_action_user_id = pd.read_csv(\"total_action_user_id.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct sessions data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has dimension: (213451, 16)\n",
      "X_test has dimension: (62096, 15)\n"
     ]
    }
   ],
   "source": [
    "df_total_action_user_id.columns = ['id','action']\n",
    "df_sessions = pd.merge(df_time_mean_user_id, df_time_total_user_id, on='id', how='outer')\n",
    "df_sessions = pd.merge(df_sessions, df_total_action_user_id, on='id', how='outer')\n",
    "df_sessions.columns = ['id','time_mean_user','time_total_user','action']\n",
    "df_sessions.head()\n",
    "\n",
    "print(\"X_train has dimension:\",df_train_users.shape)\n",
    "print(\"X_test has dimension:\",df_test_users.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. From data frame to matrix : Construct y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want now for the training is 2 matrices X_train (matrix of relevant features) and y_train (booking dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_labels, label_enc = machine_learning_helper.buildTargetMat(df_train_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. From data frame to matrix : Construct X_train & X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering.\n",
    "Add 3 features : \n",
    "- time_mean_user\n",
    "- time_total_user\n",
    "- total_action_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_len = df_train_users.shape[0]\n",
    "df_train = df_train_users.drop(['country_destination'],axis=1)\n",
    "df_all = pd.concat((df_train_users, df_test_users), axis=0, ignore_index=True)\n",
    "df_all = pd.merge(df_all, df_sessions, on='id', how='left', left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = machine_learning_helper.buildFeatsMat(df_train_users, df_test_users, df_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "5 folds cross validation, using ndcg as scoring metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train = X_train[100000:100100]\n",
    "#y_labels = y_labels[100000:100100]\n",
    "#X_test = X_test[10000:60000]\n",
    "\n",
    "# Split train dataset into 5 folds \n",
    "cv = model_selection.KFold(n_splits=5, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning \n",
    "First several algorithms are tried, and optimized through Cross validation and Grid Search. The code is here optimized to run on 3 processors at the same time, as it is very long. See here examples on MacBook Pro 4 cpu, RAM 16GB\n",
    "Computational time\n",
    "GridsearchCrossValidation:\n",
    "\n",
    "- 5000 data\n",
    "    Random Forest : 27 fits 10,1s\n",
    "    XGB : 36 fits 60s\n",
    "    \n",
    "- 10000 data\n",
    "    Random Forest : 27 fits 22 s\n",
    "    XGB : 36 fits 140s\n",
    "    \n",
    "- 50000 data\n",
    "    Random Forest : 27 fits 342\n",
    "    XGB : 36 fits 1100s\n",
    "\n",
    "Our final model is composed of a voting classifier composed of the previous models optimized.\n",
    "\n",
    "\n",
    "Models that were tried:\n",
    "- **Random Forest** with the following parameters:\n",
    "\n",
    "    - 'max_depth': [ 4, 6, 8]\n",
    "    - 'n_estimators': [ 50, 100, 150]\n",
    "\n",
    "\n",
    "- **eXtreme Gradient Boosting XCGB**:\n",
    "    - 'max_depth': [6,8,10],\n",
    "    - 'learning_rate': [0.3],\n",
    "    - 'n_estimators': [10,15,20,25],\n",
    "    - 'objective': ['multi:softprob'],\n",
    "    - 'gamma': [0],\n",
    "    - 'subsample': [0.5],\n",
    "    - 'colsample_bytree': [0.5],\n",
    "    - 'seed': [0]\n",
    "\n",
    "- Voting classifer:\n",
    "    - Soft \n",
    "    \n",
    "The metric used is the nDCG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 : RandomForest\n",
    "\n",
    "Grid Search to find best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse = sp.sparse.csr_matrix(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_trees_idx:  1 / 10 , value:  50\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.777909, total= 1.4min\n",
      "[CV] ................................. , score=0.831268, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  1.5min remaining:  2.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.842008, total= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  1.6min remaining:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.833026, total= 1.7min\n",
      "[CV] ................................. , score=0.811310, total= 1.7min\n",
      "Mean NDCG for this number_trees =  0.819104173364\n",
      "number_trees_idx:  2 / 10 , value:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.778842, total= 2.4min\n",
      "[CV] ................................. , score=0.832232, total= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  2.4min remaining:  3.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.841025, total= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  2.6min remaining:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.831988, total= 2.7min\n",
      "[CV] ................................. , score=0.811423, total= 2.7min\n",
      "Mean NDCG for this number_trees =  0.819102124937\n",
      "number_trees_idx:  3 / 10 , value:  125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  2.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.779809, total= 2.9min\n",
      "[CV] ................................. , score=0.832256, total= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  3.0min remaining:  4.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.841894, total= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  3.1min remaining:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.832281, total= 3.2min\n",
      "[CV] ................................. , score=0.811400, total= 3.2min\n",
      "Mean NDCG for this number_trees =  0.819528040116\n",
      "number_trees_idx:  4 / 10 , value:  150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  3.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.779745, total= 3.4min\n",
      "[CV] ................................. , score=0.832238, total= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  3.5min remaining:  5.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.842500, total= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  3.6min remaining:  2.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.831737, total= 3.7min\n",
      "[CV] ................................. , score=0.811626, total= 3.8min\n",
      "Mean NDCG for this number_trees =  0.819569226263\n",
      "number_trees_idx:  5 / 10 , value:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  3.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.779984, total= 4.4min\n",
      "[CV] ................................. , score=0.832073, total= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  4.5min remaining:  6.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.843092, total= 4.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  4.7min remaining:  3.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.831667, total= 4.8min\n",
      "[CV] ................................. , score=0.812168, total= 4.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  4.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this number_trees =  0.819796880111\n",
      "number_trees_idx:  6 / 10 , value:  300\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.832798, total= 6.5min\n",
      "[CV] ................................. , score=0.779705, total= 6.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  6.6min remaining:  9.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.843440, total= 6.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  6.9min remaining:  4.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.831769, total= 7.0min\n",
      "[CV] ................................. , score=0.812716, total= 7.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  7.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this number_trees =  0.820085744256\n",
      "number_trees_idx:  7 / 10 , value:  400\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.779883, total= 8.4min\n",
      "[CV] ................................. , score=0.832839, total= 8.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  8.7min remaining: 13.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.844207, total= 8.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  8.8min remaining:  5.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.832152, total= 9.2min\n",
      "[CV] ................................. , score=0.813151, total= 9.3min\n",
      "Mean NDCG for this number_trees =  0.82044653311\n",
      "number_trees_idx:  8 / 10 , value:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  9.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.779809, total=11.0min\n",
      "[CV] ................................. , score=0.833054, total=11.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed: 11.1min remaining: 16.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.844278, total=11.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed: 11.5min remaining:  7.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.832415, total=12.3min\n",
      "[CV] ................................. , score=0.813185, total=12.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 12.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 12.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this number_trees =  0.82054805219\n",
      "number_trees_idx:  9 / 10 , value:  600\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.780157, total=12.7min\n",
      "[CV] ................................. , score=0.833097, total=12.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed: 13.0min remaining: 19.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.844201, total=13.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed: 13.3min remaining:  8.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.832254, total=13.6min\n",
      "[CV] ................................. , score=0.813263, total=13.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 13.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 13.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this number_trees =  0.820594408655\n",
      "number_trees_idx:  10 / 10 , value:  700\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.780104, total=14.3min\n",
      "[CV] ................................. , score=0.833215, total=15.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed: 15.0min remaining: 22.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.844377, total=15.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed: 15.1min remaining: 10.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.813303, total=15.6min\n",
      "[CV] ................................. , score=0.832347, total=15.8min\n",
      "Mean NDCG for this number_trees =  0.82066913368\n",
      "\n",
      "best NDCG:\n",
      "0.82066913368\n",
      "best parameter num_trees:\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 15.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 15.8min finished\n"
     ]
    }
   ],
   "source": [
    "number_trees = [ 50, 100, 125, 150, 200, 300, 400, 500, 600, 700]\n",
    "max_depth = [6, 8, 10, 12, 14, 16, 20, 22]\n",
    "\n",
    "\n",
    "rf_score_trees = []\n",
    "rf_score_depth = []\n",
    "rf_param_trees = []\n",
    "rf_param_depth = []\n",
    "\n",
    "#Loop for 1st hyperparameter n_estimators\n",
    "for number_trees_idx, number_trees_value in enumerate(number_trees):\n",
    "    \n",
    "    print('number_trees_idx: ',number_trees_idx+1,'/',len(number_trees),', value: ', number_trees_value)\n",
    "\n",
    "    # Random forest\n",
    "    rand_forest_model = ensemble.RandomForestClassifier(n_estimators=number_trees_value, max_depth=14)\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(rand_forest_model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_trees.append(scores.mean())\n",
    "    rf_param_trees.append(number_trees_value)\n",
    "    print('Mean NDCG for this number_trees = ', scores.mean())\n",
    "\n",
    "# best number of trees from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_trees))\n",
    "print('best parameter num_trees:')\n",
    "idx_best = np.argmax(rf_score_trees)\n",
    "best_num_trees = rf_param_trees[idx_best]\n",
    "print(best_num_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth_idx:  1 / 7 , value:  6\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.828698, total= 2.2min\n",
      "[CV] ................................. , score=0.821918, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  2.4min remaining:  3.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.818011, total= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  2.9min remaining:  1.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.766861, total= 3.0min\n",
      "[CV] ................................. , score=0.798396, total= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  3.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this max:_depth =  0.806776580659\n",
      "max_depth_idx:  2 / 7 , value:  8\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.826189, total= 3.8min\n",
      "[CV] ................................. , score=0.833133, total= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  3.9min remaining:  5.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.818392, total= 4.3min\n",
      "[CV] ................................. , score=0.798421, total= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  4.4min remaining:  2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.767152, total= 4.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  4.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this max:_depth =  0.808657412526\n",
      "max_depth_idx:  3 / 7 , value:  10\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.837733, total= 5.4min\n",
      "[CV] ................................. , score=0.830226, total= 5.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  5.6min remaining:  8.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.822767, total= 6.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  6.4min remaining:  4.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.774418, total= 6.5min\n",
      "[CV] ................................. , score=0.805268, total= 7.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  7.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this max:_depth =  0.814082406942\n",
      "max_depth_idx:  4 / 7 , value:  12\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.831468, total= 9.0min\n",
      "[CV] ................................. , score=0.841676, total= 9.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  9.2min remaining: 13.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.778407, total= 9.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  9.6min remaining:  6.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.828714, total=10.2min\n",
      "[CV] ................................. , score=0.808415, total=10.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 10.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this max:_depth =  0.817736152901\n",
      "max_depth_idx:  5 / 7 , value:  14\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.780104, total=14.8min\n",
      "[CV] ................................. , score=0.844377, total=15.8min\n",
      "[CV] ................................. , score=0.833215, total=15.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed: 16.0min remaining: 24.0min\n",
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed: 16.0min remaining: 10.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.832347, total=16.5min\n",
      "[CV] ................................. , score=0.813303, total=17.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 17.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 17.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this max:_depth =  0.82066913368\n",
      "max_depth_idx:  6 / 7 , value:  16\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.781131, total=24.1min\n",
      "[CV] ................................. , score=0.832784, total=24.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed: 24.7min remaining: 37.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.845441, total=25.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed: 25.3min remaining: 16.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.833810, total=25.9min\n",
      "[CV] ................................. , score=0.814198, total=26.5min\n",
      "Mean NDCG for this max:_depth =  0.821472784776\n",
      "max_depth_idx:  7 / 7 , value:  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 26.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 26.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.779178, total=55.3min\n",
      "[CV] ................................. , score=0.831379, total=57.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed: 57.8min remaining: 86.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.844476, total=59.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed: 59.1min remaining: 39.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.833236, total=60.2min\n",
      "[CV] ................................. , score=0.813526, total=61.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 61.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 61.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this max:_depth =  0.820359044301\n",
      "\n",
      "best NDCG:\n",
      "0.821472784776\n",
      "best parameter max_depth:\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "#Loop for 2nd hyperparameter max_depth\n",
    "for max_depth_idx, max_depth_value in enumerate(max_depth):\n",
    "    \n",
    "    print('max_depth_idx: ',max_depth_idx+1,'/',len(max_depth),', value: ', max_depth_value)\n",
    "\n",
    "    # Random forest\n",
    "    rand_forest_model = ensemble.RandomForestClassifier(n_estimators=best_num_trees, max_depth=max_depth_value)\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(rand_forest_model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_depth.append(scores.mean())\n",
    "    rf_param_depth.append(max_depth_value)\n",
    "    print('Mean NDCG for this max:_depth = ', scores.mean())\n",
    "    \n",
    "# best max_depth from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_depth))\n",
    "print('best parameter max_depth:')\n",
    "idx_best = np.argmax(rf_score_depth)\n",
    "best_max_depth = rf_param_depth[idx_best]\n",
    "print(best_max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 : eXtreme Gradient Boosting XCGB\n",
    "\n",
    "5 folds cross validation, using ndcg as scoring metric.\n",
    "\n",
    "Grid Search to find best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators_idx:  1 / 8 , value:  10\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.845056, total= 1.7min\n",
      "[CV] ................................. , score=0.833197, total= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  1.7min remaining:  2.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.780059, total= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  2.0min remaining:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.835081, total= 2.0min\n",
      "[CV] ................................. , score=0.814447, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this n_estimators =  0.821568051733\n",
      "n_estimators_idx:  2 / 8 , value:  50\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.844250, total= 6.8min\n",
      "[CV] ................................. , score=0.832724, total= 6.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  6.9min remaining: 10.3min\n",
      "Process ForkPoolWorker-221:\n",
      "Process ForkPoolWorker-228:\n",
      "Process ForkPoolWorker-226:\n",
      "Process ForkPoolWorker-227:\n",
      "Process ForkPoolWorker-223:\n",
      "Process ForkPoolWorker-220:\n",
      "Process ForkPoolWorker-222:\n",
      "Process ForkPoolWorker-225:\n",
      "Process ForkPoolWorker-224:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-218:\n",
      "Process ForkPoolWorker-219:\n",
      "Process ForkPoolWorker-217:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 682, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 602, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 599, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/threading.py\", line 549, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/threading.py\", line 293, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 606, in terminate\n",
      "    super(MemmapingPool, self).terminate()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 505, in terminate\n",
      "    self._terminate()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/util.py\", line 186, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 535, in _terminate_pool\n",
      "    cls._help_stuff_finish(inqueue, task_handler, len(pool))\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 520, in _help_stuff_finish\n",
      "    inqueue._rlock.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-120c91e1c418>\", line 21, in <module>\n",
      "    scores = model_selection.cross_val_score(model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 140, in cross_val_score\n",
      "    for train, test in cv_iter)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 768, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 718, in retrieve\n",
      "    backend.abort_everything(ensure_ready=ensure_ready)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 143, in abort_everything\n",
      "    self.terminate()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 317, in terminate\n",
      "    super(MultiprocessingBackend, self).terminate()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 134, in terminate\n",
      "    self._pool.terminate()  # terminate does a join()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 608, in terminate\n",
      "    except WindowsError as e:\n",
      "TypeError: catching classes that do not inherit from BaseException is not allowed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/inspect.py\", line 709, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/py/_apipkg.py\", line 171, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/py/_apipkg.py\", line 155, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/py/_apipkg.py\", line 48, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/pytest.py\", line 21, in <module>\n",
      "    from _pytest.config import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 661, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 765, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 476, in _compile_bytecode\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 682, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 602, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 599, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/threading.py\", line 549, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/threading.py\", line 293, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 606, in terminate\n",
      "    super(MemmapingPool, self).terminate()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 505, in terminate\n",
      "    self._terminate()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/util.py\", line 186, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 535, in _terminate_pool\n",
      "    cls._help_stuff_finish(inqueue, task_handler, len(pool))\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 520, in _help_stuff_finish\n",
      "    inqueue._rlock.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-120c91e1c418>\", line 21, in <module>\n",
      "    scores = model_selection.cross_val_score(model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 140, in cross_val_score\n",
      "    for train, test in cv_iter)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 768, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 718, in retrieve\n",
      "    backend.abort_everything(ensure_ready=ensure_ready)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 143, in abort_everything\n",
      "    self.terminate()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 317, in terminate\n",
      "    super(MultiprocessingBackend, self).terminate()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 134, in terminate\n",
      "    self._pool.terminate()  # terminate does a join()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 608, in terminate\n",
      "    except WindowsError as e:\n",
      "TypeError: catching classes that do not inherit from BaseException is not allowed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_code\n",
      "    self.showtraceback()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1824, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1406, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1314, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1176, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: Can't convert 'list' object to str implicitly\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 342, in fix_frame_records_filenames\n",
      "    filename = py3compat.cast_unicode_py2(filename, \"utf-8\")\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [ 0.1,0.2,0.3,0.4]\n",
    "max_depth = [6, 8, 10, 12, 14, 16, 20]\n",
    "n_estimators = [10,50,75,100,150,200,300,600]\n",
    "\n",
    "rf_score_rates = []\n",
    "rf_score_depth = []\n",
    "rf_score_estimators = []\n",
    "rf_param_rates = []\n",
    "rf_param_depth = []\n",
    "rf_param_estimators = []\n",
    "\n",
    "#Loop for 1st hyperparameter n_estimators\n",
    "for n_estimators_idx, n_estimators_value in enumerate(n_estimators):\n",
    "    \n",
    "    print('n_estimators_idx: ',n_estimators_idx+1,'/',len(n_estimators),', value: ', n_estimators_value)\n",
    "\n",
    "    # XCGB\n",
    "    model = XGBClassifier(max_depth=10, learning_rate=0.2, n_estimators=n_estimators_value,objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, seed=0)\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_estimators.append(scores.mean())\n",
    "    rf_param_estimators.append(n_estimators_value)\n",
    "    print('Mean NDCG for this n_estimators = ', scores.mean())\n",
    "\n",
    "# best number of estimators from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_estimators))\n",
    "print('best parameter num_estimators:')\n",
    "idx_best = np.argmax(rf_score_estimators)\n",
    "best_num_estimators = rf_param_estimators[idx_best]\n",
    "print(best_num_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth_idx:  1 / 7 , value:  6\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 26\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-238:\n",
      "Process ForkPoolWorker-240:\n",
      "Process ForkPoolWorker-239:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-236:\n",
      "Process ForkPoolWorker-235:\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-237:\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-234:\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ca9f1d2a0acd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndcg_scorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mrf_score_depth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrf_param_depth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# check if timeout supported in backend future implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Loop for  hyperparameter max_depth\n",
    "for max_depth_idx, max_depth_value in enumerate(max_depth):\n",
    "    \n",
    "    print('max_depth_idx: ',max_depth_idx+1,'/',len(max_depth),', value: ', max_depth_value)\n",
    "\n",
    "    # XCGB\n",
    "    model = XGBClassifier(max_depth=max_depth_value, learning_rate=0.2, n_estimators=10,objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, seed=0)\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_depth.append(scores.mean())\n",
    "    rf_param_depth.append(max_depth_value)\n",
    "    print('Mean NDCG for this max_depth = ', scores.mean())\n",
    "\n",
    "# best number of estimators from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_depth))\n",
    "print('best parameter max_depth:')\n",
    "idx_best = np.argmax(rf_score_depth)\n",
    "best_num_depth = rf_param_depth[idx_best]\n",
    "print(best_num_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rates_idx:  1 / 4 , value:  0.1\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n"
     ]
    }
   ],
   "source": [
    "#Loop for  hyperparameter learning rate\n",
    "for learning_rates_idx, learning_rates_value in enumerate(learning_rates):\n",
    "    \n",
    "    print('learning_rates_idx: ',learning_rates_idx+1,'/',len(learning_rates),', value: ', learning_rates_value)\n",
    "\n",
    "    # Random forest\n",
    "    model = XGBClassifier(max_depth=6, learning_rate=learning_rates_value, n_estimators=10)\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_rates.append(scores.mean())\n",
    "    rf_param_rates.append(learning_rates_value)\n",
    "    print('Mean NDCG for this learning rate = ', scores.mean())\n",
    "\n",
    "# best number of trees from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_rates))\n",
    "print('best parameter learning rates:')\n",
    "idx_best = np.argmax(rf_score_rates)\n",
    "best_learning_rate = rf_param_rates[idx_best]\n",
    "print(best_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 : SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting\n",
    "Now we are going to vote between the 2 models optimized with their best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create the sub models\n",
    "estimators = []\n",
    "model1 = ensemble.RandomForestClassifier(max_depth=gridSearchRandomForest.best_estimator_.max_depth, \n",
    "                                         n_estimators=gridSearchRandomForest.best_estimator_.n_estimators)\n",
    "estimators.append(('random_forest', model1))\n",
    "\n",
    "model2 = XGBClassifier(max_depth=gridSearchXGB.best_estimator_.max_depth, \n",
    "                       learning_rate=gridSearchXGB.best_estimator_.learning_rate,\n",
    "                      n_estimators= gridSearchXGB.best_estimator_.n_estimators,\n",
    "                      objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, seed=0)\n",
    "estimators.append(('xgb', model2))\n",
    "# Create Voting classifier\n",
    "finalModel1 = ensemble.VotingClassifier(estimators,voting='soft')\n",
    "results = model_selection.cross_val_score(finalModel, X_train, y_labels, cv=cv, scoring = metrics_helper.ndcg_scorer, verbose = 10)\n",
    "print(\"Voting Classifier Cross Validation Score found:\")\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict countries from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalModel1.fit(X_train,y_labels)\n",
    "y_pred1 = finalModel1.predict_proba(X_test)  \n",
    "id_test = df_test_users['id']\n",
    "cts1,idsubmission1 = machine_learning_helper.get5likelycountries(y_pred1, id_test)\n",
    "\n",
    "ctsSubmission1 = label_enc.inverse_transform(cts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalModel2 = model2\n",
    "finalModel2.fit(X_train,y_labels)\n",
    "y_pred2 = finalModel.predict_proba(X_test)  \n",
    "cts2,idsubmission2 = machine_learning_helper.get5likelycountries(y_pred2, id_test)\n",
    "\n",
    "ctsSubmission2 = label_enc.inverse_transform(cts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submission1 = pd.DataFrame(np.column_stack((idsubmission1, ctsSubmission1)), columns=['id', 'country'])\n",
    "df_submission1.to_csv('submission_country_dest1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submission2 = pd.DataFrame(np.column_stack((idsubmission2, ctsSubmission2)), columns=['id', 'country'])\n",
    "df_submission2.to_csv('submission_country_dest2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Results with :\n",
    "    \n",
    "    - **Voting (model1, model2) : 0.86735**\n",
    "    Random Forest:\n",
    "        Random Forest Best Score found: 0.795119516323\n",
    "        Random Forest Best parameters set found:\n",
    "        {'n_estimators': 50, 'max_depth': 8} \n",
    "    XGB:\n",
    "        eXtreme Gradient Boosting Best Score found: 0.802158514839\n",
    "        {'learning_rate': 0.3, 'colsample_bytree': 0.5, 'objective': 'multi:softprob', 'gamma': 0, 'n_estimators': 20, 'subsample': 0.5, 'seed': 0, 'max_depth': 6}\n",
    "    Voting Classifier:\n",
    "        Voting Classifier Cross Validation Score found: 0.802676551693\n",
    "\n",
    "    \n",
    "    - **model2 : 0.86735**\n",
    "    XGB:\n",
    "        eXtreme Gradient Boosting Best Score found: 0.802158514839\n",
    "        {'learning_rate': 0.3, 'colsample_bytree': 0.5, 'objective': 'multi:softprob', 'gamma': 0, 'n_estimators': 20, 'subsample': 0.5, 'seed': 0, 'max_depth': 6}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
