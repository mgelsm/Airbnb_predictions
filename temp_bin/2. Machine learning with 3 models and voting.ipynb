{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import machine_learning_helper as machine_learning_helper\n",
    "import metrics_helper as metrics_helper\n",
    "import sklearn.neighbors, sklearn.linear_model, sklearn.ensemble, sklearn.naive_bayes\n",
    "from sklearn.model_selection import KFold, train_test_split, ShuffleSplit\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import scipy as sp\n",
    "import xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_users = pd.read_csv(\"cleaned_train_user.csv\")\n",
    "df_test_users = pd.read_csv(\"cleaned_test_user.csv\")\n",
    "df_time_mean_user_id = pd.read_csv(\"time_mean_user_id.csv\")\n",
    "df_time_total_user_id = pd.read_csv(\"time_total_user_id.csv\")\n",
    "df_total_action_user_id = pd.read_csv(\"total_action_user_id.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct sessions data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has dimension: (213451, 16)\n",
      "X_test has dimension: (62096, 15)\n"
     ]
    }
   ],
   "source": [
    "df_total_action_user_id.columns = ['id','action']\n",
    "df_sessions = pd.merge(df_time_mean_user_id, df_time_total_user_id, on='id', how='outer')\n",
    "df_sessions = pd.merge(df_sessions, df_total_action_user_id, on='id', how='outer')\n",
    "df_sessions.columns = ['id','time_mean_user','time_total_user','action']\n",
    "df_sessions.head()\n",
    "\n",
    "print(\"X_train has dimension:\",df_train_users.shape)\n",
    "print(\"X_test has dimension:\",df_test_users.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. From data frame to matrix : Construct y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want now for the training is 2 matrices X_train (matrix of relevant features) and y_train (booking dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_labels, label_enc = machine_learning_helper.buildTargetMat(df_train_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. From data frame to matrix : Construct X_train & X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering.\n",
    "Add 3 features : \n",
    "- time_mean_user\n",
    "- time_total_user\n",
    "- total_action_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_len = df_train_users.shape[0]\n",
    "df_train = df_train_users.drop(['country_destination'],axis=1)\n",
    "df_all = pd.concat((df_train_users, df_test_users), axis=0, ignore_index=True)\n",
    "df_all = pd.merge(df_all, df_sessions, on='id', how='left', left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = machine_learning_helper.buildFeatsMat(df_train_users, df_test_users, df_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "5 folds cross validation, using ndcg as scoring metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ..., 213448 213449 213450] [     3      7      9 ..., 213443 213444 213445]\n",
      "[     0      3      5 ..., 213446 213449 213450] [     1      2      4 ..., 213441 213447 213448]\n",
      "[     0      1      2 ..., 213447 213448 213450] [     6     17     24 ..., 213426 213446 213449]\n",
      "[     1      2      3 ..., 213447 213448 213449] [     0      5      8 ..., 213433 213437 213450]\n",
      "[     0      1      2 ..., 213448 213449 213450] [    11     13     16 ..., 213434 213438 213440]\n"
     ]
    }
   ],
   "source": [
    "#X_train = X_train[100000:110000]\n",
    "#y_labels = y_labels[100000:110000]\n",
    "\n",
    "# Split train dataset into 5 folds, completely shuffled\n",
    "cv = model_selection.KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "for train_id, test_id in cv.split(X_train):\n",
    "    print(train_id, test_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning \n",
    "First several algorithms are tried, and optimized through Cross validation and Grid Search. The code is here optimized to run on 3 processors at the same time, as it is very long. See here examples on MacBook Pro 4 cpu, RAM 16GB\n",
    "Computational time\n",
    "GridsearchCrossValidation:\n",
    "\n",
    "- 5000 data\n",
    "    Random Forest : 27 fits 10,1s\n",
    "    XGB : 36 fits 60s\n",
    "    \n",
    "- 10000 data\n",
    "    Random Forest : 27 fits 22 s\n",
    "    XGB : 36 fits 140s\n",
    "    \n",
    "- 50000 data\n",
    "    Random Forest : 27 fits 342\n",
    "    XGB : 36 fits 1100s\n",
    "\n",
    "Our final model is composed of a voting classifier composed of the previous models optimized.\n",
    "\n",
    "\n",
    "Models that were tried:\n",
    "- **Random Forest** with the following parameters:\n",
    "\n",
    "    - 'max_depth': [ 4, 6, 8]\n",
    "    - 'n_estimators': [ 50, 100, 150]\n",
    "\n",
    "\n",
    "- **eXtreme Gradient Boosting XCGB**:\n",
    "    - 'max_depth': [6,8,10],\n",
    "    - 'learning_rate': [0.3],\n",
    "    - 'n_estimators': [10,15,20,25],\n",
    "    - 'objective': ['multi:softprob'],\n",
    "    - 'gamma': [0],\n",
    "    - 'subsample': [0.5],\n",
    "    - 'colsample_bytree': [0.5],\n",
    "    - 'seed': [0]\n",
    "\n",
    "- Voting classifer:\n",
    "    - Soft \n",
    "    \n",
    "The metric used is the nDCG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 : RandomForest\n",
    "\n",
    "Grid Search to find best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse = sp.sparse.csr_matrix(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_trees = [125, 300, 500, 600  ]\n",
    "max_depth = [5, 8, 12, 16, 20]\n",
    "\n",
    "rf_score_trees = []\n",
    "rf_score_depth = []\n",
    "rf_param_trees = []\n",
    "rf_param_depth = []\n",
    "\n",
    "#Loop for 1st hyperparameter n_estimators\n",
    "for number_trees_idx, number_trees_value in enumerate(number_trees):\n",
    "    \n",
    "    print('number_trees_idx: ',number_trees_idx+1,'/',len(number_trees),', value: ', number_trees_value)\n",
    "\n",
    "    # Random forest\n",
    "    rand_forest_model = ensemble.RandomForestClassifier(n_estimators=number_trees_value, max_depth=14)\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(rand_forest_model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_trees.append(scores.mean())\n",
    "    rf_param_trees.append(number_trees_value)\n",
    "    print('Mean NDCG for this number_trees = ', scores.mean())\n",
    "\n",
    "# best number of trees from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_trees))\n",
    "print('best parameter num_trees:')\n",
    "idx_best = np.argmax(rf_score_trees)\n",
    "best_num_trees_RF = rf_param_trees[idx_best]\n",
    "print(best_num_trees_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loop for  hyperparameter max_depth\n",
    "for max_depth_idx, max_depth_value in enumerate(max_depth):\n",
    "    \n",
    "    print('max_depth_idx: ',max_depth_idx+1,'/',len(max_depth),', value: ', max_depth_value)\n",
    "\n",
    "    # Random forest\n",
    "    rand_forest_model = ensemble.RandomForestClassifier(n_estimators=best_num_trees_RF, max_depth=max_depth_value)\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(rand_forest_model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_depth.append(scores.mean())\n",
    "    rf_param_depth.append(max_depth_value)\n",
    "    print('Mean NDCG for this max:_depth = ', scores.mean())\n",
    "    \n",
    "# best max_depth from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_depth))\n",
    "print('best parameter max_depth:')\n",
    "idx_best = np.argmax(rf_score_depth)\n",
    "best_max_depth_RF = rf_param_depth[idx_best]\n",
    "print(best_max_depth_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest 600 trees, 16 depth NDCG = 0.821472784776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Countries and convert to CSV for submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_num_trees_RF = 600\n",
    "best_max_depth_RF = 16\n",
    "\n",
    "rand_forest_model = ensemble.RandomForestClassifier(n_estimators=best_num_trees_RF, max_depth=best_max_depth_RF)\n",
    "rand_forest_model.fit(X_train_sparse,y_labels)\n",
    "y_pred1 = rand_forest_model.predict_proba(X_test)  \n",
    "id_test = df_test_users['id']\n",
    "cts1,idsubmission1 = machine_learning_helper.get5likelycountries(y_pred1, id_test)\n",
    "\n",
    "ctsSubmission1 = label_enc.inverse_transform(cts1)\n",
    "\n",
    "\n",
    "df_submission1 = pd.DataFrame(np.column_stack((idsubmission1, ctsSubmission1)), columns=['id', 'country'])\n",
    "df_submission1.to_csv('submission_country_dest_RF.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 : eXtreme Gradient Boosting XCGB\n",
    "\n",
    "5 folds cross validation, using ndcg as scoring metric.\n",
    "\n",
    "Grid Search to find best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.01, 0.05,0.1, 0.2]\n",
    "max_depth = [3, 5, 7, 9, 12]\n",
    "n_estimators = [20,30,50,75,100]\n",
    "gamma = [0,0.3, 0.5, 0.7, 1]\n",
    "\n",
    "rf_score_rates = []\n",
    "rf_score_depth = []\n",
    "rf_score_estimators = []\n",
    "rf_score_gamma = []\n",
    "rf_param_rates = []\n",
    "rf_param_depth = []\n",
    "rf_param_estimators = []\n",
    "rf_param_gamma = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth_idx:  1 / 5 , value:  3\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.825536, total= 4.3min\n",
      "[CV] ................................. , score=0.824440, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  4.4min remaining:  6.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825843, total= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  4.5min remaining:  3.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.827577, total= 4.5min\n",
      "[CV] ................................. , score=0.825573, total= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  4.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this max_depth =  0.825793832774\n",
      "max_depth_idx:  2 / 5 , value:  5\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.826692, total= 5.9min\n",
      "[CV] ................................. , score=0.826686, total= 6.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  6.1min remaining:  9.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825197, total= 6.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  6.1min remaining:  4.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825876, total= 6.1min\n",
      "[CV] ................................. , score=0.826545, total= 6.3min\n",
      "Mean NDCG for this max_depth =  0.826199066592\n",
      "max_depth_idx:  3 / 5 , value:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  6.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.826934, total= 7.3min\n",
      "[CV] ................................. , score=0.825241, total= 7.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  7.3min remaining: 11.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825647, total= 7.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  7.4min remaining:  4.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.826031, total= 7.4min\n",
      "[CV] ................................. , score=0.827572, total= 7.4min\n",
      "Mean NDCG for this max_depth =  0.826284851913\n",
      "max_depth_idx:  4 / 5 , value:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  7.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.826261, total= 8.7min\n",
      "[CV] ................................. , score=0.825134, total= 9.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  9.0min remaining: 13.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.827389, total= 9.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  9.0min remaining:  6.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.824617, total= 9.0min\n",
      "[CV] ................................. , score=0.826377, total= 9.0min\n",
      "Mean NDCG for this max_depth =  0.825955572991\n",
      "max_depth_idx:  5 / 5 , value:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  9.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.825927, total=10.8min\n",
      "[CV] ................................. , score=0.823658, total=10.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed: 10.9min remaining: 16.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.823432, total=11.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed: 11.0min remaining:  7.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.821969, total=11.0min\n",
      "[CV] ................................. , score=0.826961, total=11.1min\n",
      "Mean NDCG for this max_depth =  0.824389547542\n",
      "\n",
      "best NDCG:\n",
      "0.826284851913\n",
      "best parameter max_depth:\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 11.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 11.1min finished\n"
     ]
    }
   ],
   "source": [
    "#Loop for  hyperparameter max_depth\n",
    "for max_depth_idx, max_depth_value in enumerate(max_depth):\n",
    "    \n",
    "    print('max_depth_idx: ',max_depth_idx+1,'/',len(max_depth),', value: ', max_depth_value)\n",
    "\n",
    "    # XCGB\n",
    "    model = XGBClassifier(max_depth=max_depth_value, learning_rate=0.1, n_estimators=100,objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, gamma=0.5 )\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_depth.append(scores.mean())\n",
    "    rf_param_depth.append(max_depth_value)\n",
    "    print('Mean NDCG for this max_depth = ', scores.mean())\n",
    "\n",
    "# best number of estimators from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_depth))\n",
    "print('best parameter max_depth:')\n",
    "idx_best = np.argmax(rf_score_depth)\n",
    "best_num_depth_XCG = rf_param_depth[idx_best]\n",
    "print(best_num_depth_XCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators_idx:  1 / 5 , value:  20\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.822629, total= 1.9min\n",
      "[CV] ................................. , score=0.821990, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  2.0min remaining:  3.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825919, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  2.0min remaining:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.824131, total= 2.1min\n",
      "[CV] ................................. , score=0.825549, total= 2.1min\n",
      "Mean NDCG for this n_estimators =  0.824043783229\n",
      "n_estimators_idx:  2 / 5 , value:  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  2.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.825394, total= 2.5min\n",
      "[CV] ................................. , score=0.824396, total= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  2.6min remaining:  4.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.826880, total= 2.7min\n",
      "[CV] ................................. , score=0.825361, total= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  2.7min remaining:  1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825667, total= 2.7min\n",
      "Mean NDCG for this n_estimators =  0.825539657253\n",
      "n_estimators_idx:  3 / 5 , value:  50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  2.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.825074, total= 3.8min\n",
      "[CV] ................................. , score=0.825888, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  4.0min remaining:  5.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.827658, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  4.0min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.826367, total= 4.0min\n",
      "[CV] ................................. , score=0.825776, total= 4.0min\n",
      "Mean NDCG for this n_estimators =  0.826152648014\n",
      "n_estimators_idx:  4 / 5 , value:  75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  4.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.828479, total= 5.7min\n",
      "[CV] ................................. , score=0.827377, total= 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  5.8min remaining:  8.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.826013, total= 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  5.8min remaining:  3.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.827077, total= 5.9min\n",
      "[CV] ................................. , score=0.822821, total= 5.9min\n",
      "Mean NDCG for this n_estimators =  0.826353492278\n",
      "n_estimators_idx:  5 / 5 , value:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.827061, total= 7.4min\n",
      "[CV] ................................. , score=0.827790, total= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  7.5min remaining: 11.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.823881, total= 7.6min\n",
      "[CV] ................................. , score=0.826231, total= 7.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  7.6min remaining:  5.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825589, total= 7.7min\n",
      "Mean NDCG for this n_estimators =  0.826110503387\n",
      "\n",
      "best NDCG:\n",
      "0.826353492278\n",
      "best parameter num_estimators:\n",
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  7.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  7.7min finished\n"
     ]
    }
   ],
   "source": [
    "#Loop for hyperparameter n_estimators\n",
    "for n_estimators_idx, n_estimators_value in enumerate(n_estimators):\n",
    "    \n",
    "    print('n_estimators_idx: ',n_estimators_idx+1,'/',len(n_estimators),', value: ', n_estimators_value)\n",
    "\n",
    "    # XCGB\n",
    "    model = XGBClassifier(max_depth=best_num_depth_XCG, learning_rate=0.1, n_estimators=n_estimators_value,objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, gamma=0.5 )\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_estimators.append(scores.mean())\n",
    "    rf_param_estimators.append(n_estimators_value)\n",
    "    print('Mean NDCG for this n_estimators = ', scores.mean())\n",
    "\n",
    "# best number of estimators from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_estimators))\n",
    "print('best parameter num_estimators:')\n",
    "idx_best = np.argmax(rf_score_estimators)\n",
    "best_num_estimators_XCG = rf_param_estimators[idx_best]\n",
    "print(best_num_estimators_XCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma_idx:  1 / 5 , value:  0\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.827068, total= 5.4min\n",
      "[CV] ................................. , score=0.826770, total= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  5.5min remaining:  8.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.824673, total= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  5.6min remaining:  3.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.827431, total= 5.6min\n",
      "[CV] ................................. , score=0.825960, total= 5.6min\n",
      "Mean NDCG for this gamma =  0.826380308232\n",
      "gamma_idx:  2 / 5 , value:  0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.825921, total= 5.4min\n",
      "[CV] ................................. , score=0.826705, total= 5.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  5.6min remaining:  8.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.824183, total= 5.6min\n",
      "[CV] ................................. , score=0.826090, total= 5.6min\n",
      "[CV] ................................. , score=0.827912, total= 5.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  5.6min remaining:  3.8min\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG for this gamma =  0.826162073693\n",
      "gamma_idx:  3 / 5 , value:  0.5\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.826908, total= 5.4min\n",
      "[CV] ................................. , score=0.825086, total= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  5.5min remaining:  8.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.827914, total= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  5.5min remaining:  3.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825519, total= 5.6min\n",
      "[CV] ................................. , score=0.826324, total= 5.6min\n",
      "Mean NDCG for this gamma =  0.826350165748\n",
      "gamma_idx:  4 / 5 , value:  0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.828562, total= 5.5min\n",
      "[CV] ................................. , score=0.826191, total= 5.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  5.7min remaining:  8.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.826148, total= 5.7min\n",
      "[CV] ................................. , score=0.823935, total= 5.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  5.7min remaining:  3.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.827004, total= 5.8min\n",
      "Mean NDCG for this gamma =  0.82636790693\n",
      "gamma_idx:  5 / 5 , value:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.826725, total= 5.5min\n",
      "[CV] ................................. , score=0.826944, total= 5.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  5.7min remaining:  8.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.827410, total= 5.7min\n",
      "[CV] ................................. , score=0.826190, total= 5.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  5.7min remaining:  3.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.824719, total= 5.7min\n",
      "Mean NDCG for this gamma =  0.826397519287\n",
      "\n",
      "best NDCG:\n",
      "0.826397519287\n",
      "best parameter gamma:\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.7min finished\n"
     ]
    }
   ],
   "source": [
    "#Loop for  hyperparameter learning rate\n",
    "for gamma_idx, gamma_value in enumerate(gamma):\n",
    "    \n",
    "    print('gamma_idx: ',gamma_idx+1,'/',len(gamma),', value: ', gamma_value)\n",
    "\n",
    "    # XGB\n",
    "    model = XGBClassifier(max_depth=best_num_depth_XCG, learning_rate=0.1, n_estimators=best_num_estimators_XCG,objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, gamma=gamma_value )\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_gamma.append(scores.mean())\n",
    "    rf_param_gamma.append(gamma_value)\n",
    "    print('Mean NDCG for this gamma = ', scores.mean())\n",
    "\n",
    "# best number of trees from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_gamma))\n",
    "print('best parameter gamma:')\n",
    "idx_best = np.argmax(rf_score_gamma)\n",
    "best_gamma_XCG = rf_param_gamma[idx_best]\n",
    "print(best_gamma_XCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rates_idx:  1 / 5 , value:  0.001\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.819375, total= 4.9min\n",
      "[CV] ................................. , score=0.819680, total= 5.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  5.0min remaining:  7.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.820594, total= 5.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  5.0min remaining:  3.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.818348, total= 5.1min\n",
      "[CV] ................................. , score=0.818750, total= 5.1min\n",
      "Mean NDCG for this learning rate =  0.819349504012\n",
      "learning_rates_idx:  2 / 5 , value:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.823754, total= 5.3min\n",
      "[CV] ................................. , score=0.822457, total= 5.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  5.4min remaining:  8.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.823466, total= 5.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  5.4min remaining:  3.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.823187, total= 5.5min\n",
      "[CV] ................................. , score=0.824220, total= 5.5min\n",
      "Mean NDCG for this learning rate =  0.823416694986\n",
      "learning_rates_idx:  3 / 5 , value:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.827183, total= 5.5min\n",
      "[CV] ................................. , score=0.826882, total= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  5.5min remaining:  8.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825618, total= 5.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  5.6min remaining:  3.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825527, total= 5.6min\n",
      "[CV] ................................. , score=0.824709, total= 5.6min\n",
      "Mean NDCG for this learning rate =  0.825983764444\n",
      "learning_rates_idx:  4 / 5 , value:  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.826467, total= 5.8min\n",
      "[CV] ................................. , score=0.826080, total= 6.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  6.0min remaining:  9.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.826904, total= 6.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  6.0min remaining:  4.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825833, total= 6.0min\n",
      "[CV] ................................. , score=0.825826, total= 6.0min\n",
      "Mean NDCG for this learning rate =  0.82622187548\n",
      "learning_rates_idx:  5 / 5 , value:  0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.824451, total= 5.6min\n",
      "[CV] ................................. , score=0.826745, total= 5.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed:  5.6min remaining:  8.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.826576, total= 5.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed:  5.7min remaining:  3.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825596, total= 5.7min\n",
      "[CV] ................................. , score=0.824270, total= 5.8min\n",
      "Mean NDCG for this learning rate =  0.825527656512\n",
      "\n",
      "best NDCG:\n",
      "0.82622187548\n",
      "best parameter learning rates:\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed:  5.8min finished\n"
     ]
    }
   ],
   "source": [
    "#Loop for  hyperparameter gamma\n",
    "for learning_rates_idx, learning_rates_value in enumerate(learning_rates):\n",
    "    \n",
    "    print('learning_rates_idx: ',learning_rates_idx+1,'/',len(learning_rates),', value: ', learning_rates_value)\n",
    "\n",
    "    # XGB\n",
    "    model = XGBClassifier(max_depth=best_num_depth_XCG, learning_rate=learning_rates_value, n_estimators=best_num_estimators_XCG,objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, gamma=best_gamma_XCG )\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_rates.append(scores.mean())\n",
    "    rf_param_rates.append(learning_rates_value)\n",
    "    print('Mean NDCG for this learning rate = ', scores.mean())\n",
    "\n",
    "# best number of trees from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_rates))\n",
    "print('best parameter learning rates:')\n",
    "idx_best = np.argmax(rf_score_rates)\n",
    "best_learning_rate_XCG = rf_param_rates[idx_best]\n",
    "print(best_learning_rate_XCG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Countries and convert to CSV for submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XGB_model = XGBClassifier(max_depth=best_num_depth_XCG, learning_rate=best_learning_rate_XCG, n_estimators=best_num_estimators_XCG,objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, gamma = best_gamma_XCG)\n",
    "XGB_model.fit(X_train,y_labels)\n",
    "y_pred2 = XGB_model.predict_proba(X_test)  \n",
    "id_test = df_test_users['id']\n",
    "cts2,idsubmission2 = machine_learning_helper.get5likelycountries(y_pred2, id_test)\n",
    "\n",
    "ctsSubmission2 = label_enc.inverse_transform(cts2)\n",
    "\n",
    "\n",
    "df_submission2 = pd.DataFrame(np.column_stack((idsubmission2, ctsSubmission2)), columns=['id', 'country'])\n",
    "df_submission2.to_csv('submission_country_dest_XGB.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 : SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_idx:  1 / 5 , value:  0.1\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-332:\n",
      "Process ForkPoolWorker-330:\n",
      "Process ForkPoolWorker-334:\n",
      "Process ForkPoolWorker-331:\n",
      "Process ForkPoolWorker-336:\n",
      "Process ForkPoolWorker-335:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-333:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mint/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "catching classes that do not inherit from BaseException is not allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMemmapingPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/multiprocessing/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    185\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'helping task handler/workers to finish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_help_stuff_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_help_stuff_finish\u001b[0;34m(inqueue, task_handler, size)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'removing tasks from inqueue until task handler finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0minqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-1ea1a4d3e33b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#Scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndcg_scorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mSVM_score_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mSVM_param_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    716\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;34m\"\"\"Shutdown the pool and restart a new one with the same parameters\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             self.configure(n_jobs=self.parallel.n_jobs, parallel=self.parallel,\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;34m\"\"\"Shutdown the process or thread pool\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiprocessingBackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# terminate does a join()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mint/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMemmapingPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mWindowsError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;31m# Workaround  occasional \"[Error 5] Access is denied\" issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                 \u001b[0;31m# when trying to terminate a process under windows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: catching classes that do not inherit from BaseException is not allowed"
     ]
    }
   ],
   "source": [
    "C = [1,1e1,1e2, 1e3]\n",
    "\n",
    "SVM_score_C = []\n",
    "SVM_param_C = []\n",
    "\n",
    "#Loop for 1st hyperparameter n_estimators\n",
    "for C_idx, C_value in enumerate(C):\n",
    "    \n",
    "    print('C_idx: ',C_idx+1,'/',len(C),', value: ', C_value)\n",
    "\n",
    "    # SVM\n",
    "    model = sklearn.svm.SVC(C = C_value, probability=True)\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    SVM_score_C.append(scores.mean())\n",
    "    SVM_param_C.append(C_value)\n",
    "    print('Mean NDCG for this C = ', scores.mean())\n",
    "\n",
    "# best number of estimators from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(SVM_score_C))\n",
    "print('best parameter C:')\n",
    "idx_best = np.argmax(SVM_score_C)\n",
    "best_C_SVM = SVM_param_C[idx_best]\n",
    "print(best_C_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Countries and convert to CSV for submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_C_SVM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-d5128feffdd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSVM_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_C_SVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSVM_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mid_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test_users\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcts3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midsubmission3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmachine_learning_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget5likelycountries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_C_SVM' is not defined"
     ]
    }
   ],
   "source": [
    "SVM_model = sklearn.svm.SVC(C = best_C_SVM, probability=True)\n",
    "SVM_model.fit(X_train_sparse,y_labels)\n",
    "y_pred3 = SVM_model.predict_proba(X_test)  \n",
    "id_test = df_test_users['id']\n",
    "cts3,idsubmission3 = machine_learning_helper.get5likelycountries(y_pred3, id_test)\n",
    "\n",
    "ctsSubmission3 = label_enc.inverse_transform(cts3)\n",
    "\n",
    "\n",
    "df_submission3 = pd.DataFrame(np.column_stack((idsubmission3, ctsSubmission3)), columns=['id', 'country'])\n",
    "df_submission3.to_csv('submission_country_dest_SVM.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVM\n",
    "model = sklearn.svm.SVC(tol=0.0001,  verbose=0, random_state=None, probability=True,max_iter=1000)\n",
    "#model.fit(X_train_sparse,y_labels)\n",
    "\n",
    "#Scores\n",
    "scores = model_selection.cross_val_score(model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 3, scoring=metrics_helper.ndcg_scorer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting\n",
    "Now we are going to vote between the 3 models optimized with their best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.826263, total=23.7min\n",
      "[CV] ................................. , score=0.827403, total=23.8min\n",
      "[CV] ................................. , score=0.825203, total=23.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of   5 | elapsed: 23.8min remaining: 35.7min\n",
      "[Parallel(n_jobs=12)]: Done   3 out of   5 | elapsed: 23.8min remaining: 15.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.826588, total=23.8min\n",
      "[CV] ................................. , score=0.824282, total=23.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 23.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of   5 | elapsed: 23.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Cross Validation Score found:\n",
      "0.82594782673\n"
     ]
    }
   ],
   "source": [
    "# Create the sub models\n",
    "estimators = []\n",
    "model1 = ensemble.RandomForestClassifier(max_depth=best_max_depth_RF, n_estimators= best_num_trees_RF)\n",
    "estimators.append(('random_forest', model1))\n",
    "\n",
    "model2 = XGBClassifier(max_depth=best_num_depth_XCG,learning_rate=best_learning_rate_XCG,n_estimators= best_num_estimators_XCG,\n",
    "                      objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, gamma = best_gamma_XCG)\n",
    "estimators.append(('xgb', model2))\n",
    "\n",
    "#model3 = sklearn.svm.SVC(C = best_C_SVM, probability=True)\n",
    "#estimators.append(('svm', model3))\n",
    "\n",
    "# Create Voting classifier\n",
    "finalModel = ensemble.VotingClassifier(estimators,voting='soft')\n",
    "\n",
    "# Run cross validation score\n",
    "results = model_selection.cross_val_score(finalModel, X_train, y_labels, cv=cv, scoring = metrics_helper.ndcg_scorer, verbose = 10, n_jobs=12)\n",
    "print(\"Voting Classifier Cross Validation Score found:\")\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict countries from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalModel.fit(X_train,y_labels)\n",
    "y_pred1 = finalModel.predict_proba(X_test)  \n",
    "id_test = df_test_users['id']\n",
    "cts1,idsubmission1 = machine_learning_helper.get5likelycountries(y_pred1, id_test)\n",
    "\n",
    "ctsSubmission1 = label_enc.inverse_transform(cts1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submission1 = pd.DataFrame(np.column_stack((idsubmission1, ctsSubmission1)), columns=['id', 'country'])\n",
    "df_submission1.to_csv('submission_country_dest_Voting.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Results with :\n",
    "    \n",
    "    - **Voting (model1, model2) : 0.86735**\n",
    "    Random Forest:\n",
    "        Random Forest Best Score found: 0.795119516323\n",
    "        Random Forest Best parameters set found:\n",
    "        {'n_estimators': 50, 'max_depth': 8} \n",
    "    XGB:\n",
    "        eXtreme Gradient Boosting Best Score found: 0.802158514839\n",
    "        {'learning_rate': 0.3, 'colsample_bytree': 0.5, 'objective': 'multi:softprob', 'gamma': 0, 'n_estimators': 20, 'subsample': 0.5, 'seed': 0, 'max_depth': 6}\n",
    "    Voting Classifier:\n",
    "        Voting Classifier Cross Validation Score found: 0.802676551693\n",
    "\n",
    "    \n",
    "    - **model2 : 0.86735**\n",
    "    XGB:\n",
    "        eXtreme Gradient Boosting Best Score found: 0.802158514839\n",
    "        {'learning_rate': 0.3, 'colsample_bytree': 0.5, 'objective': 'multi:softprob', 'gamma': 0, 'n_estimators': 20, 'subsample': 0.5, 'seed': 0, 'max_depth': 6}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
