{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning \n",
    "This file builds the training dataset from the multiple csv files of the kaggle challenge. It applies four different prediction models and evaluates the importance of the 156 features built and the learning curve of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import machine_learning_helper as machine_learning_helper\n",
    "import metrics_helper as metrics_helper\n",
    "import sklearn.neighbors, sklearn.linear_model, sklearn.ensemble, sklearn.naive_bayes\n",
    "from sklearn.model_selection import KFold, train_test_split, ShuffleSplit\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import scipy as sp\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn import linear_model, datasets\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataFolder = 'cleaned_data'\n",
    "resultFolder = 'results'\n",
    "filenameAdress_train_user = 'cleaned_train_user.csv'\n",
    "filenameAdress_test_user = 'cleaned_test_user.csv'\n",
    "filenameAdress_time_mean_user_id = 'time_mean_user_id.csv'\n",
    "filenameAdress_time_total_user_id = 'time_total_user_id.csv'\n",
    "filenameAdress_total_action_user_id = 'total_action_user_id.csv'\n",
    "\n",
    "df_train_users = pd.read_csv(os.path.join(dataFolder, filenameAdress_train_user))\n",
    "df_test_users = pd.read_csv(os.path.join(dataFolder, filenameAdress_test_user))\n",
    "df_time_mean_user_id = pd.read_csv(os.path.join(dataFolder, filenameAdress_time_mean_user_id))\n",
    "df_time_total_user_id = pd.read_csv(os.path.join(dataFolder, filenameAdress_time_total_user_id))\n",
    "df_total_action_user_id = pd.read_csv(os.path.join(dataFolder, filenameAdress_total_action_user_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct sessions data frame\n",
    "This dataframe contains the features that were extracted from the file sessions. For more information about these features, see notebook Main preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_total_action_user_id.columns = ['id','action']\n",
    "df_sessions = pd.merge(df_time_mean_user_id, df_time_total_user_id, on='id', how='outer')\n",
    "df_sessions = pd.merge(df_sessions, df_total_action_user_id, on='id', how='outer')\n",
    "df_sessions.columns = ['id','time_mean_user','time_total_user','action']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. From data frame to matrix : Construct y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The destination countries, now as string, are encoded in int format. Each country will be assigned to a int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_labels, label_enc = machine_learning_helper.buildTargetMat(df_train_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. From data frame to matrix : Construct X_train & X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering.\n",
    "Added features : \n",
    "- time_mean_user\n",
    "- time_total_user\n",
    "- total_action_user\n",
    "- Date created account\n",
    "- Date first active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = machine_learning_helper.buildFeatsMat(df_train_users, df_test_users, df_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train[200000:201000]\n",
    "y_labels = y_labels[200000:201000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Memory purpose, the train matrix is formatted in sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse = sp.sparse.csr_matrix(X_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross validation setup\n",
    "5 folds cross validation, shuffled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = model_selection.KFold(n_splits=5, random_state=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning \n",
    "Several models are tried, and their parameter optimized through Cross validation. The code is optimized to run on 12 processors at the same time. The metric used is the NDCG. Because of the computation complexity, the for loops for the cross validations were not nested.\n",
    "\n",
    "\n",
    "Models that were tried:\n",
    "- **Random Forest**\n",
    "- **eXtreme Gradient Boosting XCGB**\n",
    "- **2 layers stack model**:\n",
    "    - Logistic regression\n",
    "    - eXtreme Gradient Boosting XCGB\n",
    "- **Voting classifer**\n",
    "    - Random Forest\n",
    "    - eXtreme Gradient Boosting XCGB\n",
    "    - 2 layers stack model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 : RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_trees = [125, 300, 500, 600 ]\n",
    "max_depth = [5, 8, 12, 16, 20]\n",
    "\n",
    "rf_score_trees = []\n",
    "rf_score_depth = []\n",
    "rf_param_trees = []\n",
    "rf_param_depth = []\n",
    "\n",
    "#Loop for hyperparameter number_trees\n",
    "for number_trees_idx, number_trees_value in enumerate(number_trees):\n",
    "    \n",
    "    print('number_trees_idx: ',number_trees_idx+1,'/',len(number_trees),', value: ', number_trees_value)\n",
    "\n",
    "    # Random forest\n",
    "    rand_forest_model = ensemble.RandomForestClassifier(n_estimators=number_trees_value, max_depth=14)\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(rand_forest_model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_trees.append(scores.mean())\n",
    "    rf_param_trees.append(number_trees_value)\n",
    "    print('Mean NDCG for this number_trees = ', scores.mean())\n",
    "\n",
    "# best number of trees from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_trees))\n",
    "print('best parameter num_trees:')\n",
    "idx_best = np.argmax(rf_score_trees)\n",
    "best_num_trees_RF = rf_param_trees[idx_best]\n",
    "print(best_num_trees_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loop for hyperparameter max_depth\n",
    "for max_depth_idx, max_depth_value in enumerate(max_depth):\n",
    "    \n",
    "    print('max_depth_idx: ',max_depth_idx+1,'/',len(max_depth),', value: ', max_depth_value)\n",
    "\n",
    "    # Random forest\n",
    "    rand_forest_model = ensemble.RandomForestClassifier(n_estimators=best_num_trees_RF, max_depth=max_depth_value)\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(rand_forest_model, X_train_sparse, y_labels, cv=cv, verbose = 10, n_jobs = 12, scoring=metrics_helper.ndcg_scorer)\n",
    "    rf_score_depth.append(scores.mean())\n",
    "    rf_param_depth.append(max_depth_value)\n",
    "    print('Mean NDCG for this max:_depth = ', scores.mean())\n",
    "    \n",
    "# best max_depth from above\n",
    "print() \n",
    "print('best NDCG:')\n",
    "print(np.max(rf_score_depth))\n",
    "print('best parameter max_depth:')\n",
    "idx_best = np.argmax(rf_score_depth)\n",
    "best_max_depth_RF = rf_param_depth[idx_best]\n",
    "print(best_max_depth_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random forest 600 trees, 16 depth **\n",
    " - **NDCG = 0.821472784776**\n",
    " - **Kaggle Private Leader Board NDCG = 0.86686**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Countries and convert to CSV for submision for RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_num_trees_RF = 600\n",
    "best_max_depth_RF = 16\n",
    "\n",
    "rand_forest_model = ensemble.RandomForestClassifier(n_estimators=best_num_trees_RF, max_depth=best_max_depth_RF)\n",
    "rand_forest_model.fit(X_train_sparse,y_labels)\n",
    "y_pred1 = rand_forest_model.predict_proba(X_test)  \n",
    "id_test = df_test_users['id']\n",
    "cts1,idsubmission1 = machine_learning_helper.get5likelycountries(y_pred1, id_test)\n",
    "\n",
    "ctsSubmission1 = label_enc.inverse_transform(cts1)\n",
    "\n",
    "# Save to csv\n",
    "df_submission1 = pd.DataFrame(np.column_stack((idsubmission1, ctsSubmission1)), columns=['id', 'country'])\n",
    "df_submission1.to_csv(os.path.join(resultFolder, 'submission_country_dest_RF.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 : eXtreme Gradient Boosting XCGB\n",
    "\n",
    "5 folds cross validation, using ndcg as scoring metric.\n",
    "\n",
    "Grid Search to find best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.01, 0.05,0.1, 0.2]\n",
    "max_depth = [3, 5, 7, 9, 12]\n",
    "n_estimators = [20,30,50,75,100]\n",
    "gamma = [0,0.3, 0.5, 0.7, 1]\n",
    "\n",
    "best_gamma_XCG, best_num_estimators_XCG,best_num_depth_XCG, best_learning_rate_XCG = machine_learning_helper.CrossVal_XGB(X_train_sparse, y_labels, cv,max_depth,n_estimators,learning_rates,gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** XGboost - learning_rate = 0.1, gamma =1, depth = 7, estimators = 75 **\n",
    " - **NDCG = TODO**\n",
    " - **Kaggle Private Leader Board NDCG = 0.86967**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Countries and convert to CSV for submision of xgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_learning_rate_XCG = 0.1\n",
    "best_num_depth_XCG = 7\n",
    "best_gamma_XCG = 1\n",
    "best_num_estimators_XCG = 75\n",
    "\n",
    "XGB_model = XGBClassifier(max_depth=best_num_depth_XCG, learning_rate=best_learning_rate_XCG, n_estimators=best_num_estimators_XCG,objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, gamma = best_gamma_XCG)\n",
    "XGB_model.fit(X_train,y_labels, eval_metric=metrics_helper.ndcg_scorer)\n",
    "y_pred2 = XGB_model.predict_proba(X_test)  \n",
    "id_test = df_test_users['id']\n",
    "cts2,idsubmission2 = machine_learning_helper.get5likelycountries(y_pred2, id_test)\n",
    "\n",
    "ctsSubmission2 = label_enc.inverse_transform(cts2)\n",
    "\n",
    "\n",
    "df_submission2 = pd.DataFrame(np.column_stack((idsubmission2, ctsSubmission2)), columns=['id', 'country'])\n",
    "df_submission2.to_csv(os.path.join(resultFolder, 'submission_country_dest_XGB.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 : Stacking \n",
    "\n",
    "As seen previously, the classes in this dataset are unbalanced. Indeed, half of the users didn't book. We are going to try to make good use of that information.\n",
    "\n",
    "This model is composed of 2 layers :\n",
    "- In a first layer, a logistic regression determines if a user is going to book or not. This binary classification model is trained on the training set. The prediction on the test set by this model is added to a second layer, as a meta feature.\n",
    "\n",
    "- The second layer is an XGBoost algorithm. It is trained on the new training set, which is made on the original one connected with the output of the first layer under the column 'meta_layer_1'.\n",
    "\n",
    "<img src=\"https://s23.postimg.org/8g018p4a3/1111.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1 : Logistic regression\n",
    "\n",
    "This logistic regressionw will determine if a user booked or not. It is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build 1st layer training matrix, text matrix, target vector\n",
    "y_labels_binary, X_train_layer1, X_test_layer1 = machine_learning_helper.buildFeatsMatBinary(df_train_users, df_test_users, df_sessions)\n",
    "y_labels_binary = y_labels_binary[200000:201000]\n",
    "X_train_layer1 = X_train_layer1[200000:201000]\n",
    "y_labels_binary = y_labels_binary.astype(np.int8)\n",
    "\n",
    "# Build 1st layer model\n",
    "# Cross validation with parameter C\n",
    "\n",
    "C = [0.1, 1.0, 10, 100, 1000]\n",
    "logistic_score_C = []\n",
    "logistic_param_C = []\n",
    "\n",
    "#Loop for hyperparameter \n",
    "for C_idx, C_value in enumerate(C):\n",
    "    \n",
    "    print('C_idx: ',C_idx+1,'/',len(C),', value: ', C_value)\n",
    "\n",
    "    # SVM\n",
    "    model = linear_model.LogisticRegression(C = C_value)\n",
    "\n",
    "    #Scores\n",
    "    scores = model_selection.cross_val_score(model, X_train_layer1, y_labels_binary, cv=cv, verbose = 10, scoring='f1', n_jobs = 12)\n",
    "    logistic_score_C.append(scores.mean())\n",
    "    logistic_param_C.append(C_value)\n",
    "    print('Mean f1 for this C = ', scores.mean())\n",
    "\n",
    "# best C from above\n",
    "print() \n",
    "print('best f1:')\n",
    "print(np.max(logistic_score_C))\n",
    "print('best parameter C:')\n",
    "idx_best = np.argmax(logistic_score_C)\n",
    "best_C_logistic = logistic_param_C[idx_best]\n",
    "print(best_C_logistic)\n",
    "\n",
    "# Build model with best parameter from cross validation\n",
    "logreg_layer1 = linear_model.LogisticRegression(C = best_C_logistic)\n",
    "logreg_layer1.fit(X_train_layer1, y_labels_binary)\n",
    "\n",
    "# 1st layer model prediction\n",
    "prediction_layer_1 = logreg_layer1.predict(X_test_layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2 : XGBoost\n",
    "\n",
    "Using the previous result as a meta_feature, this model will determine the 5 most likely countries in which a user will travel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_num_depth_XCG = 7\n",
    "best_learning_rate_XCG = 0.1\n",
    "best_num_estimators_XCG = 75\n",
    "best_gamma_XCG = 1\n",
    "\n",
    "# Build 2nd layer training matrix, text matrix, target vector\n",
    "X_train_layer2 = X_train_layer1\n",
    "X_train_layer2['meta_layer_1'] = pd.Series(y_labels_binary).astype(np.int8)\n",
    "X_test_layer2 = X_test_layer1\n",
    "X_test_layer2['meta_layer_1'] = pd.Series(prediction_layer_1).astype(np.int8)\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.05,0.1, 0.2]\n",
    "max_depth = [3, 5, 7, 9, 12]\n",
    "n_estimators = [20,30,50,75,100]\n",
    "gamma = [0,0.3, 0.5, 0.7, 1]\n",
    "cv2 = model_selection.KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "best_gamma_XCG, best_num_estimators_XCG,best_num_depth_XCG, best_learning_rate_XCG = machine_learning_helper.CrossVal_XGB(X_train_layer2, y_labels, cv2,max_depth,n_estimators,learning_rates,gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2 layers stack model - learning_rate = TODO, gamma =TODO, depth = TODO, estimators = TODO **\n",
    " - **NDCG = TODO**\n",
    " - **Kaggle Private Leader Board NDCG = TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Countries and convert to CSV for submision of 2 Layer Stack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XGB_model = XGBClassifier(max_depth=best_num_depth_XCG, learning_rate=best_learning_rate_XCG, n_estimators=best_num_estimators_XCG,objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, gamma = best_gamma_XCG)\n",
    "XGB_model.fit(X_train_layer2,y_labels, eval_metric=metrics_helper.ndcg_scorer)\n",
    "y_pred2 = XGB_model.predict_proba(X_test_layer2)  \n",
    "id_test = df_test_users['id']\n",
    "cts2,idsubmission2 = machine_learning_helper.get5likelycountries(y_pred2, id_test)\n",
    "\n",
    "ctsSubmission2 = label_enc.inverse_transform(cts2)\n",
    "\n",
    "\n",
    "df_submission2 = pd.DataFrame(np.column_stack((idsubmission2, ctsSubmission2)), columns=['id', 'country'])\n",
    "df_submission2.to_csv(os.path.join(resultFolder, 'submission_country_dest_stacking.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Voting Model\n",
    "Now we are going to vote between the 3 models optimized with their best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the sub models\n",
    "estimators = []\n",
    "model1 = ensemble.RandomForestClassifier(max_depth=best_max_depth_RF, n_estimators= best_num_trees_RF)\n",
    "estimators.append(('random_forest', model1))\n",
    "\n",
    "model2 = XGBClassifier(max_depth=best_num_depth_XCG,learning_rate=best_learning_rate_XCG,n_estimators= best_num_estimators_XCG,\n",
    "                      objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, gamma = best_gamma_XCG)\n",
    "estimators.append(('xgb', model2))\n",
    "\n",
    "model3 = XGB_model\n",
    "estimators.append(('2layer', model3))\n",
    "\n",
    "# Create Voting classifier\n",
    "finalModel = ensemble.VotingClassifier(estimators,voting='soft')\n",
    "\n",
    "# Run cross validation score\n",
    "results = model_selection.cross_val_score(finalModel, X_train, y_labels, cv=cv, scoring = metrics_helper.ndcg_scorer, verbose = 10, n_jobs=12)\n",
    "print(\"Voting Classifier Cross Validation Score found:\")\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Voting classifier **\n",
    " - **NDCG = TODO**\n",
    " - **Kaggle Private Leader Board NDCG = TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict countries from Voting model and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalModel.fit(X_train,y_labels)\n",
    "y_pred1 = finalModel.predict_proba(X_test)  \n",
    "id_test = df_test_users['id']\n",
    "cts1,idsubmission1 = machine_learning_helper.get5likelycountries(y_pred1, id_test)\n",
    "\n",
    "ctsSubmission1 = label_enc.inverse_transform(cts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submission1 = pd.DataFrame(np.column_stack((idsubmission1, ctsSubmission1)), columns=['id', 'country'])\n",
    "df_submission1.to_csv(os.path.join(resultFolder, 'submission_country_dest_Voting.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Evaluating features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=7, learning_rate=0.1, n_estimators=75,objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, gamma=1 )\n",
    "model.fit(X_train,y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "machine_learning_helper.plotFeaturesImportance(model,X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows the 20 most important features following the NDCG score. The age feature is by far the most important one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below shows the most important features using the F score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "xgb.plot_importance(model,height=0.7, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "machine_learning_helper.plotFeaturesImportance(XGB_model,X_train_layer2)\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "xgb.plot_importance(XGB_model,height=0.7, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The features importance plots of the 2 Layer stack model show that the importance of the features is much better distributed over 4 main features instead of 1. \n",
    "- The meta_layer_1 feature comes fourth in the importance feature ranking and justifies the 2 layers approach.\n",
    "# 6. Evaluating models learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "machine_learning_helper.plotLearningCurve(model,X_train,y_labels,cv,title='XGB model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The learning curve shown below uses a span of 80 to 800 samples from the training data. We couldn't evaluate over the whole data size, but the NDCG score grows higher with our best models and the full training dataset. \n",
    "- The figure shows that we are not overfitting on our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "machine_learning_helper.plotLearningCurve(XGB_model,X_train_layer2,y_labels,cv,title='2L Stack model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion : \n",
    "- With our best models, we can predict the destination choosen by Airbnb users with a precision of 0.86967 on the NDCG score.\n",
    "- The most important features to predict the destination are the age of the user and the day he created his account and the the time spent by the users, the action and the meta_layer_1 feature for the 2L stack model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
