{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import machine_learning_helper as machine_learning_helper\n",
    "import metrics_helper as metrics_helper\n",
    "import sklearn.neighbors, sklearn.linear_model, sklearn.ensemble, sklearn.naive_bayes\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold, train_test_split, ShuffleSplit\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_users = pd.read_csv(\"cleaned_train_user.csv\")\n",
    "df_test_users = pd.read_csv(\"cleaned_test_user.csv\")\n",
    "df_time_mean_user_id = pd.read_csv(\"time_mean_user_id.csv\")\n",
    "df_time_total_user_id = pd.read_csv(\"time_total_user_id.csv\")\n",
    "df_total_action_user_id = pd.read_csv(\"total_action_user_id.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct sessions data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has dimension: (213451, 16)\n",
      "X_test has dimension: (62096, 15)\n"
     ]
    }
   ],
   "source": [
    "df_total_action_user_id.columns = ['id','action']\n",
    "df_sessions = pd.merge(df_time_mean_user_id, df_time_total_user_id, on='id', how='outer')\n",
    "df_sessions = pd.merge(df_sessions, df_total_action_user_id, on='id', how='outer')\n",
    "df_sessions.columns = ['id','time_mean_user','time_total_user','action']\n",
    "df_sessions.head()\n",
    "\n",
    "print(\"X_train has dimension:\",df_train_users.shape)\n",
    "print(\"X_test has dimension:\",df_test_users.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. From data frame to matrix : Construct y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want now for the training is 2 matrices X_train (matrix of relevant features) and y_train (booking dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_labels, label_enc = machine_learning_helper.buildTargetMat(df_train_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. From data frame to matrix : Construct X_train & X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering.\n",
    "Add 3 features : \n",
    "- time_mean_user\n",
    "- time_total_user\n",
    "- total_action_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_len = df_train_users.shape[0]\n",
    "df_train = df_train_users.drop(['country_destination'],axis=1)\n",
    "df_all = pd.concat((df_train_users, df_test_users), axis=0, ignore_index=True)\n",
    "df_all = pd.merge(df_all, df_sessions, on='id', how='left', left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = machine_learning_helper.buildFeatsMat(df_train_users, df_test_users, df_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "5 folds cross validation, using ndcg as scoring metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train[10000:60000]\n",
    "y_labels = y_labels[10000:60000]\n",
    "X_test = X_test[10000:60000]\n",
    "\n",
    "# Split train dataset into 3 folds \n",
    "cv = model_selection.KFold(n_splits=3, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning \n",
    "First several algorithms are tried, and optimized through Cross validation and Grid Search. \n",
    "\n",
    "Our final model is composed of a voting classifier composed of the previous models optimized.\n",
    "\n",
    "Models that were tried:\n",
    "- Random Forest with the following parameters:\n",
    "\n",
    "    - 'max_depth': [ 4, 6, 8]\n",
    "    - 'n_estimators': [ 50, 100, 150]\n",
    "\n",
    "\n",
    "- eXtreme Gradient Boosting XCGB:\n",
    "    - 'max_depth': [6,8,10],\n",
    "    - 'learning_rate': [0.3],\n",
    "    - 'n_estimators': [10,15,20,25],\n",
    "    - 'objective': ['multi:softprob'],\n",
    "    - 'gamma': [0],\n",
    "    - 'subsample': [0.5],\n",
    "    - 'colsample_bytree': [0.5],\n",
    "    - 'seed': [0]\n",
    "\n",
    "- Voting classifer:\n",
    "    - Soft \n",
    "    \n",
    "The metric used is the nDCG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 : RandomForest\n",
    "\n",
    "Grid Search to find best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] n_estimators=50, max_depth=4 ....................................\n",
      "[CV] n_estimators=50, max_depth=4 ....................................\n",
      "[CV] n_estimators=50, max_depth=4 ....................................\n",
      "[CV] ........... n_estimators=50, max_depth=4, score=0.758837 -   6.7s\n",
      "[CV] n_estimators=100, max_depth=4 ...................................\n",
      "[CV] ........... n_estimators=50, max_depth=4, score=0.807243 -   6.6s\n",
      "[CV] n_estimators=100, max_depth=4 ...................................\n",
      "[CV] ........... n_estimators=50, max_depth=4, score=0.802874 -   6.7s\n",
      "[CV] n_estimators=100, max_depth=4 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:   33.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... n_estimators=100, max_depth=4, score=0.758747 -   6.5s\n",
      "[CV] n_estimators=150, max_depth=4 ...................................\n",
      "[CV] .......... n_estimators=100, max_depth=4, score=0.800109 -   6.3s\n",
      "[CV] n_estimators=150, max_depth=4 ...................................\n",
      "[CV] .......... n_estimators=100, max_depth=4, score=0.807313 -   6.4s\n",
      "[CV] n_estimators=150, max_depth=4 ...................................\n",
      "[CV] .......... n_estimators=150, max_depth=4, score=0.758608 -   6.3s\n",
      "[CV] n_estimators=50, max_depth=6 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... n_estimators=150, max_depth=4, score=0.807313 -   6.3s\n",
      "[CV] .......... n_estimators=150, max_depth=4, score=0.802008 -   6.2s\n",
      "[CV] n_estimators=50, max_depth=6 ....................................\n",
      "[CV] n_estimators=50, max_depth=6 ....................................\n",
      "[CV] ........... n_estimators=50, max_depth=6, score=0.805435 -   7.0s\n",
      "[CV] ........... n_estimators=50, max_depth=6, score=0.760681 -   6.8s\n",
      "[CV] ........... n_estimators=50, max_depth=6, score=0.807127 -   6.8s\n",
      "[CV] n_estimators=100, max_depth=6 ...................................\n",
      "[CV] n_estimators=100, max_depth=6 ...................................\n",
      "[CV] n_estimators=100, max_depth=6 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:  2.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... n_estimators=100, max_depth=6, score=0.805567 -   8.7s\n",
      "[CV] n_estimators=150, max_depth=6 ...................................\n",
      "[CV] .......... n_estimators=100, max_depth=6, score=0.807363 -   8.8s\n",
      "[CV] .......... n_estimators=100, max_depth=6, score=0.761121 -   8.4s\n",
      "[CV] n_estimators=150, max_depth=6 ...................................\n",
      "[CV] n_estimators=150, max_depth=6 ...................................\n",
      "[CV] .......... n_estimators=150, max_depth=6, score=0.804919 -   6.6s\n",
      "[CV] n_estimators=50, max_depth=8 ....................................\n",
      "[CV] .......... n_estimators=150, max_depth=6, score=0.807175 -   6.6s\n",
      "[CV] n_estimators=50, max_depth=8 ....................................\n",
      "[CV] .......... n_estimators=150, max_depth=6, score=0.761374 -   6.7s\n",
      "[CV] n_estimators=50, max_depth=8 ....................................\n",
      "[CV] ........... n_estimators=50, max_depth=8, score=0.807776 -   5.7s\n",
      "[CV] n_estimators=100, max_depth=8 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed:  4.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... n_estimators=50, max_depth=8, score=0.812423 -   6.1s\n",
      "[CV] n_estimators=100, max_depth=8 ...................................\n",
      "[CV] ........... n_estimators=50, max_depth=8, score=0.765160 -   6.1s\n",
      "[CV] n_estimators=100, max_depth=8 ...................................\n",
      "[CV] .......... n_estimators=100, max_depth=8, score=0.766011 -   6.3s\n",
      "[CV] n_estimators=150, max_depth=8 ...................................\n",
      "[CV] .......... n_estimators=100, max_depth=8, score=0.808071 -   6.0s\n",
      "[CV] n_estimators=150, max_depth=8 ...................................\n",
      "[CV] .......... n_estimators=100, max_depth=8, score=0.809802 -   6.1s\n",
      "[CV] n_estimators=150, max_depth=8 ...................................\n",
      "[CV] .......... n_estimators=150, max_depth=8, score=0.764560 -   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  25 out of  27 | elapsed:  5.7min remaining:   27.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... n_estimators=150, max_depth=8, score=0.810400 -   6.4s\n",
      "[CV] .......... n_estimators=150, max_depth=8, score=0.807945 -   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  27 out of  27 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=True),\n",
       "       fit_params={}, iid=True, n_jobs=3,\n",
       "       param_grid={'n_estimators': [50, 100, 150], 'max_depth': [4, 6, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(ndcg_score, needs_proba=True, k=5), verbose=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters to tune the model\n",
    "tune_parameters = {'max_depth': [ 4, 6, 8], 'n_estimators': [ 50, 100, 150]}\n",
    "\n",
    "# Define random forest model\n",
    "model = ensemble.RandomForestClassifier(warm_start=True)\n",
    "\n",
    "# Define GridSearch with crossValidation\n",
    "gridSearchRandomForest = model_selection.GridSearchCV(model, tune_parameters, cv=cv,scoring=metrics_helper.ndcg_scorer, n_jobs=3, verbose = 10)\n",
    "\n",
    "# Fit model to data\n",
    "gridSearchRandomForest.fit(X_train, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Score found:\n",
      "0.795119516323\n",
      "Random Forest Best parameters set found:\n",
      "{'n_estimators': 50, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Best Score found:\")\n",
    "print(gridSearchRandomForest.best_score_)\n",
    "print(\"Random Forest Best parameters set found:\")\n",
    "print(gridSearchRandomForest.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 : eXtreme Gradient Boosting XCGB\n",
    "\n",
    "5 folds cross validation, using ndcg as scoring metric.\n",
    "\n",
    "Grid Search to find best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=6, seed=0, subsample=0.5 \n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=6, seed=0, subsample=0.5 \n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=6, seed=0, subsample=0.5 \n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=6, seed=0, subsample=0.5, score=0.808574 -   7.2s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=15, max_depth=6, seed=0, subsample=0.5 \n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=6, seed=0, subsample=0.5, score=0.771561 -   7.3s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=15, max_depth=6, seed=0, subsample=0.5 \n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=6, seed=0, subsample=0.5, score=0.819610 -   7.3s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=15, max_depth=6, seed=0, subsample=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=15, max_depth=6, seed=0, subsample=0.5, score=0.772696 -   7.4s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=20, max_depth=6, seed=0, subsample=0.5 \n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=15, max_depth=6, seed=0, subsample=0.5, score=0.811706 -   7.3s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=20, max_depth=6, seed=0, subsample=0.5 \n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=15, max_depth=6, seed=0, subsample=0.5, score=0.820233 -   7.5s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=20, max_depth=6, seed=0, subsample=0.5 \n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=20, max_depth=6, seed=0, subsample=0.5, score=0.773761 -   7.8s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=25, max_depth=6, seed=0, subsample=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  4.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=20, max_depth=6, seed=0, subsample=0.5, score=0.812808 -   7.8s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=25, max_depth=6, seed=0, subsample=0.5 \n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=20, max_depth=6, seed=0, subsample=0.5, score=0.819907 -   7.6s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=25, max_depth=6, seed=0, subsample=0.5 \n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=25, max_depth=6, seed=0, subsample=0.5, score=0.812784 -   7.1s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=8, seed=0, subsample=0.5 \n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=25, max_depth=6, seed=0, subsample=0.5, score=0.773226 -   7.0s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=8, seed=0, subsample=0.5 \n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=25, max_depth=6, seed=0, subsample=0.5, score=0.818443 -   7.0s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=8, seed=0, subsample=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:  6.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=8, seed=0, subsample=0.5, score=0.772323 -   6.8s\n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=8, seed=0, subsample=0.5, score=0.807176 -   6.8s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=15, max_depth=8, seed=0, subsample=0.5 \n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=15, max_depth=8, seed=0, subsample=0.5 \n",
      "[CV]  learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=10, max_depth=8, seed=0, subsample=0.5, score=0.818599 -   6.6s\n",
      "[CV] learning_rate=0.3, colsample_bytree=0.5, objective=multi:softprob, gamma=0, n_estimators=15, max_depth=8, seed=0, subsample=0.5 \n"
     ]
    }
   ],
   "source": [
    "# Define parameters to tune the model\n",
    "tune_parameters = {\n",
    "    'max_depth': [6,8,10],\n",
    "    'learning_rate': [0.3],\n",
    "    'n_estimators': [10,15,20,25],\n",
    "    'objective': ['multi:softprob'],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.5],\n",
    "    'colsample_bytree': [0.5],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "# Define eXtreme Gradient Boosting model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Define GridSearch with crossValidation\n",
    "gridSearchXGB = model_selection.GridSearchCV(model, tune_parameters, cv=cv,scoring=metrics_helper.ndcg_scorer, n_jobs=3, verbose = 10)\n",
    "\n",
    "# Fit model to data\n",
    "gridSearchXGB.fit(X_train, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"eXtreme Gradient Boosting Best Score found:\")\n",
    "print(gridSearchXGB.best_score_)\n",
    "print(\"eXtreme Gradient Boosting Best set found:\")\n",
    "print(gridSearchXGB.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting\n",
    "Now we are going to vote between the 2 models optimized with their best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the sub models\n",
    "estimators = []\n",
    "model1 = ensemble.RandomForestClassifier(max_depth=gridSearchRandomForest.best_estimator_.max_depth, \n",
    "                                         n_estimators=gridSearchRandomForest.best_estimator_.n_estimators)\n",
    "estimators.append(('random_forest', model1))\n",
    "\n",
    "model2 = XGBClassifier(max_depth=gridSearchXGB.best_estimator_.max_depth, \n",
    "                       learning_rate=gridSearchXGB.best_estimator_.learning_rate,\n",
    "                      n_estimators= gridSearchXGB.best_estimator_.n_estimators,\n",
    "                      objective='multi:softprob',\n",
    "                      subsample=0.5, colsample_bytree=0.5, seed=0)\n",
    "estimators.append(('xgb', model2))\n",
    "# Create Voting classifier\n",
    "finalModel = ensemble.VotingClassifier(estimators,voting='soft')\n",
    "results = model_selection.cross_val_score(finalModel, X_train, y_labels, cv=cv, scoring = metrics_helper.ndcg_scorer)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict countries from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalModel.fit(X_train,y_labels)\n",
    "y_pred = finalModel.predict_proba(X_test)  \n",
    "id_test = df_test_users['id']\n",
    "cts,idsubmission = machine_learning_helper.get5likelycountries(y_pred, id_test)\n",
    "\n",
    "ctsSubmission = label_enc.inverse_transform(cts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(np.column_stack((idsubmission, ctsSubmission)), columns=['id', 'country'])\n",
    "df_submission.to_csv('submission_country_dest.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df_submission = pd.DataFrame(np.column_stack((ids, ctsSubmission)), columns=['id', 'country'])\n",
    "df_submission.to_csv('submission_country_dest.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
